<!DOCTYPE html>
<html lang="en" class="dark">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>EAGLES AI Platform - Runbook v1.0</title>
<script src="https://cdn.tailwindcss.com"></script>
<style>
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&family=JetBrains+Mono:wght@400;500;600&display=swap');
body{font-family:'Inter',sans-serif;background:#0a0a0f;scroll-behavior:smooth}
code,pre{font-family:'JetBrains Mono',monospace}
.glass{background:rgba(255,255,255,0.03);backdrop-filter:blur(20px);border:1px solid rgba(255,255,255,0.08)}
.glass-accent{background:rgba(99,102,241,0.08);border:1px solid rgba(99,102,241,0.2)}
.glass-green{background:rgba(16,185,129,0.08);border:1px solid rgba(16,185,129,0.2)}
.glass-amber{background:rgba(245,158,11,0.08);border:1px solid rgba(245,158,11,0.2)}
.glass-rose{background:rgba(244,63,94,0.08);border:1px solid rgba(244,63,94,0.2)}
.glass-cyan{background:rgba(6,182,212,0.08);border:1px solid rgba(6,182,212,0.2)}
.glass-purple{background:rgba(168,85,247,0.08);border:1px solid rgba(168,85,247,0.2)}
.glass-orange{background:rgba(249,115,22,0.08);border:1px solid rgba(249,115,22,0.2)}
.glow{box-shadow:0 0 40px rgba(99,102,241,0.1)}
.stat-number{font-size:2.5rem;font-weight:800;background:linear-gradient(135deg,#818cf8,#6366f1,#4f46e5);-webkit-background-clip:text;-webkit-text-fill-color:transparent}
.stat-sm{font-size:1.5rem;font-weight:800;background:linear-gradient(135deg,#818cf8,#6366f1,#4f46e5);-webkit-background-clip:text;-webkit-text-fill-color:transparent}
.pulse{animation:pulse 2s infinite}
@keyframes pulse{0%,100%{opacity:1}50%{opacity:0.7}}
.nav-link{transition:all .2s;padding:4px 12px;border-radius:8px;font-size:12px;color:#9ca3af}
.nav-link:hover,.nav-link.active{color:#818cf8;background:rgba(99,102,241,0.1)}
.copy-btn{position:absolute;top:8px;right:8px;background:rgba(99,102,241,0.3);color:#c7d2fe;border:none;padding:4px 10px;border-radius:6px;font-size:11px;cursor:pointer;opacity:0.6;transition:opacity .2s}
.copy-btn:hover{opacity:1}
.copy-btn.copied{background:rgba(16,185,129,0.4);color:#a7f3d0}
pre{background:rgba(0,0,0,0.4);border-radius:8px;padding:16px;overflow-x:auto;font-size:12px;line-height:1.6;position:relative;border:1px solid rgba(255,255,255,0.05)}
.cold-start-bar{height:24px;border-radius:4px;display:flex;align-items:center;padding:0 8px;font-size:10px;font-weight:600;color:white;white-space:nowrap}
.section-anchor{scroll-margin-top:80px}
table{width:100%;border-collapse:collapse}
th{text-align:left;padding:8px 12px;font-size:11px;text-transform:uppercase;letter-spacing:0.05em;color:#9ca3af;border-bottom:1px solid rgba(255,255,255,0.1)}
td{padding:8px 12px;font-size:13px;border-bottom:1px solid rgba(255,255,255,0.05)}
tr:hover td{background:rgba(99,102,241,0.03)}
.tag{font-size:10px;padding:2px 8px;border-radius:4px;font-weight:600}
</style>
</head>
<body class="text-gray-300 min-h-screen">

<!-- Sticky Nav -->
<nav class="fixed top-0 left-0 right-0 z-50 glass" style="background:rgba(10,10,15,0.9);backdrop-filter:blur(20px)">
<div class="max-w-7xl mx-auto px-4 py-2 flex items-center gap-2 overflow-x-auto">
<div class="w-6 h-6 rounded-lg bg-gradient-to-br from-indigo-500 to-purple-600 flex items-center justify-center text-white font-bold text-xs flex-shrink-0">E</div>
<span class="text-xs font-bold text-white mr-4 flex-shrink-0">AI Platform</span>
<a href="#overview" class="nav-link flex-shrink-0">Overview</a>
<a href="#architecture" class="nav-link flex-shrink-0">Architecture</a>
<a href="#costs" class="nav-link flex-shrink-0">Costs</a>
<a href="#setup" class="nav-link flex-shrink-0">Setup</a>
<a href="#smart-scale" class="nav-link flex-shrink-0">SMART-SCALE</a>
<a href="#operations" class="nav-link flex-shrink-0">Operations</a>
<a href="#troubleshooting" class="nav-link flex-shrink-0">Troubleshoot</a>
<a href="#manifests" class="nav-link flex-shrink-0">Manifests</a>
</div>
</nav>

<div class="max-w-7xl mx-auto p-4 pt-16">

<!-- HEADER -->
<div class="glass rounded-2xl p-6 glow mb-6">
<div class="flex items-center justify-between flex-wrap gap-4">
<div>
<div class="flex items-center gap-3 mb-2">
<div class="w-10 h-10 rounded-xl bg-gradient-to-br from-indigo-500 to-purple-600 flex items-center justify-center text-white font-bold text-lg">E</div>
<h1 class="text-3xl font-extrabold text-white">EAGLES <span class="text-indigo-400">AI Platform</span></h1>
<span class="text-xs px-2 py-0.5 rounded bg-gradient-to-r from-emerald-500 to-green-600 text-white font-bold">RUNBOOK v1.0</span>
</div>
<p class="text-gray-400 text-sm">Azure GPU Inference | vLLM + LiteLLM + SMART-SCALE</p>
<p class="text-gray-500 text-xs mt-1">Open-Source Models (95%) + Claude Max Fallback (5%) | Updated 2026-02-19</p>
</div>
<div class="flex gap-6 text-center">
<div><div class="stat-number">$176</div><div class="text-xs text-gray-500">/mo (low)</div></div>
<div><div class="stat-number">A100</div><div class="text-xs text-gray-500">80GB GPU</div></div>
<div><div class="stat-number">92.7</div><div class="text-xs text-gray-500">% HumanEval</div></div>
<div><div class="stat-number">6</div><div class="text-xs text-gray-500">Developers</div></div>
</div>
</div>
</div>

<!-- Quick Status Cards -->
<div class="grid grid-cols-2 md:grid-cols-4 gap-3 mb-6">
<div class="glass-green rounded-xl p-4 text-center">
<div class="text-xs text-emerald-400 font-bold mb-1">Region</div>
<div class="text-lg font-bold text-white">Central US</div>
<div class="text-[10px] text-gray-500">Cheapest A100 globally</div>
</div>
<div class="glass-accent rounded-xl p-4 text-center">
<div class="text-xs text-indigo-400 font-bold mb-1">Spot Price</div>
<div class="text-lg font-bold text-white">$0.767/hr</div>
<div class="text-[10px] text-gray-500">82% savings vs on-demand</div>
</div>
<div class="glass-purple rounded-xl p-4 text-center">
<div class="text-xs text-purple-400 font-bold mb-1">Model</div>
<div class="text-lg font-bold text-white">Qwen2.5-32B</div>
<div class="text-[10px] text-gray-500">AWQ Marlin quantized</div>
</div>
<div class="glass-cyan rounded-xl p-4 text-center">
<div class="text-xs text-cyan-400 font-bold mb-1">Cold Start</div>
<div class="text-lg font-bold text-white">3-5 min</div>
<div class="text-[10px] text-gray-500">Deallocate mode</div>
</div>
</div>

<!-- SECTION 1: OVERVIEW -->
<div id="overview" class="section-anchor glass rounded-2xl p-6 mb-6">
<div class="flex items-center gap-2 mb-4">
<div class="w-2 h-2 rounded-full bg-indigo-400 pulse"></div>
<h2 class="text-xl font-bold text-indigo-400">Platform Overview</h2>
</div>

<div class="grid md:grid-cols-2 gap-4 mb-4">
<div class="glass-accent rounded-xl p-4">
<h3 class="text-sm font-bold text-indigo-300 mb-2">Why This Platform?</h3>
<ul class="text-xs text-gray-400 space-y-1">
<li>&#8226; 95% of coding tasks handled by Qwen2.5-Coder-32B (92.7% HumanEval)</li>
<li>&#8226; Self-hosted = no rate limits, no data leaving cluster for code</li>
<li>&#8226; Azure startup credits cover ALL GPU costs ($0 new out-of-pocket)</li>
<li>&#8226; Claude Max subscription (~90 EUR/mo) as 5% fallback (already paid)</li>
<li>&#8226; SMART-SCALE: GPU auto-starts on request, auto-stops after 15min idle</li>
</ul>
</div>
<div class="glass-green rounded-xl p-4">
<h3 class="text-sm font-bold text-emerald-300 mb-2">Model Stack</h3>
<table>
<thead><tr><th>Role</th><th>Model</th><th>VRAM</th></tr></thead>
<tbody>
<tr><td class="text-emerald-300">Primary Coder</td><td class="text-xs">Qwen2.5-Coder-32B-AWQ</td><td>~20GB</td></tr>
<tr><td class="text-cyan-300">Reasoning</td><td class="text-xs">DeepSeek-R1-Distill-32B-AWQ</td><td>~18GB</td></tr>
<tr><td class="text-amber-300">Fast Complete</td><td class="text-xs">Qwen2.5-Coder-1.5B</td><td>~1GB</td></tr>
<tr><td class="text-purple-300">Embeddings</td><td class="text-xs">nomic-embed-text-v1.5</td><td>~0.3GB</td></tr>
<tr><td class="text-rose-300">Fallback (5%)</td><td class="text-xs">Claude Opus 4.6 (Max Sub)</td><td>N/A</td></tr>
</tbody>
</table>
</div>
</div>

<div class="glass rounded-xl p-4">
<h3 class="text-sm font-bold text-white mb-2">Azure Resources</h3>
<div class="grid grid-cols-2 md:grid-cols-3 gap-3">
<div class="glass-accent rounded-lg p-3"><div class="text-[10px] text-gray-500">Resource Group</div><div class="text-xs font-mono text-indigo-300">rg-eagles-ai-inference</div></div>
<div class="glass-accent rounded-lg p-3"><div class="text-[10px] text-gray-500">AKS Cluster</div><div class="text-xs font-mono text-indigo-300">aks-eagles-inference</div></div>
<div class="glass-accent rounded-lg p-3"><div class="text-[10px] text-gray-500">Container Registry</div><div class="text-xs font-mono text-indigo-300">acreaglesinference</div></div>
<div class="glass-accent rounded-lg p-3"><div class="text-[10px] text-gray-500">GPU VM</div><div class="text-xs font-mono text-indigo-300">Standard_NC24ads_A100_v4</div></div>
<div class="glass-accent rounded-lg p-3"><div class="text-[10px] text-gray-500">Namespace</div><div class="text-xs font-mono text-indigo-300">ai-inference</div></div>
<div class="glass-accent rounded-lg p-3"><div class="text-[10px] text-gray-500">Region</div><div class="text-xs font-mono text-emerald-300">Central US</div></div>
</div>
</div>
</div>

<!-- SECTION 2: ARCHITECTURE -->
<div id="architecture" class="section-anchor glass rounded-2xl p-6 mb-6">
<div class="flex items-center gap-2 mb-4">
<div class="w-2 h-2 rounded-full bg-purple-400 pulse"></div>
<h2 class="text-xl font-bold text-purple-400">Architecture</h2>
</div>

<div class="glass-purple rounded-xl p-4 mb-4">
<h3 class="text-sm font-bold text-purple-300 mb-3">Request Flow</h3>
<pre class="text-emerald-300" style="font-size:11px;line-height:1.4">
Developers (6x Claude Code CLI)
        |
        | ANTHROPIC_BASE_URL=http://litellm-gw:4000
        | ANTHROPIC_AUTH_TOKEN=$LITELLM_MASTER_KEY
        v
+---------------------------------------+
|     LiteLLM Gateway (CPU pod x2)      |
|  - /v1/messages (Anthropic format)    |
|  - Fallback chain: vLLM -&gt; Claude API |
|  - Request logging + cost tracking    |
|  - Admin UI at :4000/ui              |
+-------|------------|------------------+
        |            |
   95% traffic    5% traffic
        |            |
        v            v
+---------------+  +------------------+
| vLLM Server   |  | Anthropic API    |
| (GPU pod)     |  | api.anthropic.com|
| A100 80GB     |  | Claude Opus 4.6  |
| Central US    |  | (Max Sub ~90EUR) |
|               |  +------------------+
| Active:                              |
| - PagedAttention (always on)         |
| - Continuous batching (256 seqs)     |
| - Prefix caching (--enable)         |
| - AWQ Marlin (GPU tensor cores)      |
+----------|---+
           |
     +-----|-----+
     | Azure PVC |
     | 256GB SSD |
     | (models)  |
     +-----------+
</pre>
</div>

<div class="grid md:grid-cols-2 gap-4 mb-4">
<div class="glass rounded-xl p-4">
<h3 class="text-sm font-bold text-cyan-300 mb-2">Why vLLM (not Ollama)</h3>
<table>
<thead><tr><th>Feature</th><th>Ollama</th><th>vLLM</th></tr></thead>
<tbody>
<tr><td class="text-xs">Concurrent requests</td><td class="text-xs text-rose-400">1 (sequential)</td><td class="text-xs text-emerald-400">256 (batched)</td></tr>
<tr><td class="text-xs">Memory efficiency</td><td class="text-xs text-rose-400">Static KV</td><td class="text-xs text-emerald-400">PagedAttention 98%</td></tr>
<tr><td class="text-xs">GPU quantization</td><td class="text-xs text-amber-400">GGUF (CPU)</td><td class="text-xs text-emerald-400">AWQ Marlin (tensor)</td></tr>
<tr><td class="text-xs">Prefix caching</td><td class="text-xs text-rose-400">No</td><td class="text-xs text-emerald-400">Yes</td></tr>
<tr><td class="text-xs">Multi-user ready</td><td class="text-xs text-rose-400">No</td><td class="text-xs text-emerald-400">Yes (production)</td></tr>
</tbody>
</table>
</div>
<div class="glass rounded-xl p-4">
<h3 class="text-sm font-bold text-amber-300 mb-2">Optimization Techniques</h3>
<div class="space-y-2">
<div class="glass-green rounded-lg p-2"><span class="text-[10px] font-bold text-emerald-400">PagedAttention</span><span class="text-[10px] text-gray-500 ml-2">Always on. KV cache as virtual memory pages. 98% utilization.</span></div>
<div class="glass-green rounded-lg p-2"><span class="text-[10px] font-bold text-emerald-400">Continuous Batching</span><span class="text-[10px] text-gray-500 ml-2">Always on. New requests join batch instantly.</span></div>
<div class="glass-accent rounded-lg p-2"><span class="text-[10px] font-bold text-indigo-400">AWQ Marlin</span><span class="text-[10px] text-gray-500 ml-2">--quantization=awq_marlin. 10-15% faster than standard AWQ.</span></div>
<div class="glass-accent rounded-lg p-2"><span class="text-[10px] font-bold text-indigo-400">Prefix Caching</span><span class="text-[10px] text-gray-500 ml-2">--enable-prefix-caching. Reuses system prompt KV.</span></div>
<div class="glass-amber rounded-lg p-2"><span class="text-[10px] font-bold text-amber-400">Spec Decode</span><span class="text-[10px] text-gray-500 ml-2">OPTIONAL. Only enable if GPU util &lt; 30%.</span></div>
</div>
</div>
</div>

<div class="glass rounded-xl p-4">
<h3 class="text-sm font-bold text-white mb-2">VM Specifications</h3>
<table>
<thead><tr><th>VM Size</th><th>vCPUs</th><th>RAM</th><th>GPU</th><th>VRAM</th><th>Storage</th><th>Network</th></tr></thead>
<tbody>
<tr>
<td class="font-mono text-xs text-indigo-300">Standard_NC24ads_A100_v4</td>
<td>24</td><td>220 GiB</td><td>1x A100 PCIe</td><td class="text-emerald-300 font-bold">80 GB</td><td>64+960GB NVMe</td><td>20 Gbps</td>
</tr>
</tbody>
</table>
</div>
</div>

<!-- SECTION 3: COSTS -->
<div id="costs" class="section-anchor glass rounded-2xl p-6 mb-6">
<div class="flex items-center gap-2 mb-4">
<div class="w-2 h-2 rounded-full bg-emerald-400 pulse"></div>
<h2 class="text-xl font-bold text-emerald-400">Cost Analysis</h2>
</div>

<div class="glass-green rounded-xl p-4 mb-4">
<h3 class="text-sm font-bold text-emerald-300 mb-3">Global A100 Spot Pricing (Top 10 Regions)</h3>
<table>
<thead><tr><th>#</th><th>Region</th><th>Spot/hr</th><th>On-Demand/hr</th><th>Savings</th><th>Note</th></tr></thead>
<tbody>
<tr class="bg-emerald-500/5"><td class="font-bold text-emerald-300">1</td><td class="font-bold text-emerald-300">Central US</td><td class="font-bold text-emerald-300">$0.767</td><td>$4.150</td><td>82%</td><td><span class="tag bg-emerald-500/20 text-emerald-300">SELECTED</span></td></tr>
<tr><td>2</td><td>Canada Central</td><td>$0.815</td><td>$4.408</td><td>82%</td><td></td></tr>
<tr><td>3</td><td>North Central US</td><td>$0.815</td><td>$4.408</td><td>82%</td><td></td></tr>
<tr><td>4</td><td>North Europe (IE)</td><td>$0.815</td><td>$4.408</td><td>82%</td><td><span class="tag bg-amber-500/20 text-amber-300">EU FALLBACK</span></td></tr>
<tr><td>5</td><td>France Central</td><td>$0.848</td><td>$4.591</td><td>82%</td><td></td></tr>
<tr><td>6</td><td>Germany West Central</td><td>$0.882</td><td>$4.775</td><td>82%</td><td></td></tr>
<tr><td>7</td><td>Italy North</td><td>$0.882</td><td>$4.775</td><td>82%</td><td></td></tr>
<tr><td>8</td><td>Poland Central</td><td>$0.882</td><td>$4.775</td><td>82%</td><td></td></tr>
<tr><td>9</td><td>Southeast Asia</td><td>$0.882</td><td>$4.775</td><td>82%</td><td></td></tr>
<tr><td>10</td><td>Korea Central</td><td>$0.916</td><td>$4.959</td><td>82%</td><td></td></tr>
<tr class="opacity-50"><td>...</td><td>West Europe (NL)</td><td class="text-rose-400">$2.420</td><td>$4.775</td><td>49%</td><td class="text-rose-400">3x more expensive</td></tr>
</tbody>
</table>
<div class="glass-amber rounded-lg p-2 mt-3">
<p class="text-xs text-amber-300"><strong>Why Central US?</strong> Network latency is irrelevant for LLM inference. GPU generates tokens in 2-10s; 115ms RTT vs 10ms = 2% overhead. Code processing only (no PII). Source: Spare Cores (25 regions verified).</p>
</div>
</div>

<div class="grid md:grid-cols-2 gap-4 mb-4">
<div class="glass rounded-xl p-4">
<h3 class="text-sm font-bold text-white mb-3">Monthly Cost Scenarios</h3>
<table>
<thead><tr><th>Scenario</th><th>GPU hrs</th><th>GPU Cost</th><th>+ Overhead</th><th>Total</th></tr></thead>
<tbody>
<tr><td class="text-xs">S1: Business hours</td><td>220</td><td>$169</td><td>$130</td><td>$299</td></tr>
<tr><td class="text-xs">S2: Always on 24/7</td><td>720</td><td>$552</td><td>$130</td><td>$682</td></tr>
<tr><td class="text-xs">S3: Scale-to-zero</td><td>88</td><td>$67</td><td>$130</td><td>$197</td></tr>
<tr class="bg-emerald-500/5"><td class="text-xs font-bold text-emerald-300">S5: SMART-SCALE (low)</td><td class="text-emerald-300">60</td><td class="text-emerald-300">$46</td><td>$130</td><td class="font-bold text-emerald-300">$176</td></tr>
<tr class="bg-emerald-500/5"><td class="text-xs font-bold text-emerald-300">S5: SMART-SCALE (med)</td><td class="text-emerald-300">120</td><td class="text-emerald-300">$92</td><td>$130</td><td class="font-bold text-emerald-300">$222</td></tr>
</tbody>
</table>
</div>
<div class="glass rounded-xl p-4">
<h3 class="text-sm font-bold text-white mb-3">Credit Runway ($25K Startup)</h3>
<table>
<thead><tr><th>Scenario</th><th>Monthly</th><th>Annual</th><th>Runway</th></tr></thead>
<tbody>
<tr class="bg-emerald-500/5"><td class="text-xs font-bold text-emerald-300">S5 Low</td><td>$176</td><td>$2,112</td><td class="font-bold text-emerald-300">11.8 years</td></tr>
<tr class="bg-emerald-500/5"><td class="text-xs font-bold text-emerald-300">S5 Med</td><td>$222</td><td>$2,664</td><td class="font-bold text-emerald-300">9.4 years</td></tr>
<tr><td class="text-xs">S1 Business</td><td>$299</td><td>$3,588</td><td>7.0 years</td></tr>
<tr><td class="text-xs">S2 Always-on</td><td>$682</td><td>$8,184</td><td>3.1 years</td></tr>
</tbody>
</table>
</div>
</div>

<div class="glass rounded-xl p-4">
<h3 class="text-sm font-bold text-white mb-3">Azure Overhead (covered by credits)</h3>
<div class="grid grid-cols-2 md:grid-cols-4 gap-3">
<div class="glass-accent rounded-lg p-3 text-center"><div class="stat-sm">$73</div><div class="text-[10px] text-gray-500">AKS Standard tier</div></div>
<div class="glass-accent rounded-lg p-3 text-center"><div class="stat-sm">$35</div><div class="text-[10px] text-gray-500">Premium SSD 256GB</div></div>
<div class="glass-accent rounded-lg p-3 text-center"><div class="stat-sm">$18</div><div class="text-[10px] text-gray-500">Internal LB</div></div>
<div class="glass-accent rounded-lg p-3 text-center"><div class="stat-sm">$4</div><div class="text-[10px] text-gray-500">Azure Monitor</div></div>
</div>
<div class="glass-green rounded-lg p-2 mt-3">
<p class="text-xs text-emerald-300"><strong>Total overhead:</strong> ~$130/mo | <strong>Out-of-pocket:</strong> $0 new | <strong>Anthropic Max:</strong> ~90 EUR/mo (already paid, can downgrade later)</p>
</div>
</div>
</div>

<!-- SECTION 4: SETUP RUNBOOK -->
<div id="setup" class="section-anchor glass rounded-2xl p-6 mb-6">
<div class="flex items-center gap-2 mb-4">
<div class="w-2 h-2 rounded-full bg-amber-400 pulse"></div>
<h2 class="text-xl font-bold text-amber-400">Setup Runbook</h2>
</div>

<!-- Phase 1 -->
<div class="glass-accent rounded-xl p-4 mb-4">
<h3 class="text-sm font-bold text-indigo-300 mb-1">Phase 1: GPU Infrastructure (Week 1)</h3>
<div class="space-y-3">

<div class="glass rounded-lg p-3">
<div class="flex items-center gap-2 mb-2"><span class="text-xs font-bold text-indigo-300">1.1</span><span class="text-xs font-bold text-white">Create Resource Group + ACR</span></div>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>az group create --name rg-eagles-ai-inference --location centralus
az acr create --resource-group rg-eagles-ai-inference \
  --name acreaglesinference --sku Basic --location centralus</code></pre>
</div></div>

<div class="glass rounded-lg p-3">
<div class="flex items-center gap-2 mb-2"><span class="text-xs font-bold text-indigo-300">1.2</span><span class="text-xs font-bold text-white">Request GPU Quota</span><span class="tag bg-rose-500/20 text-rose-300">BLOCKER: 1-3 days</span></div>
<div class="glass-amber rounded-lg p-2 mb-2"><p class="text-[10px] text-amber-300">GPU VM quota is 0 by default. Request increase BEFORE creating GPU node pools.</p></div>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code># Portal: Quotas -&gt; Request increase -&gt; NC A100 v4 -&gt; Central US -&gt; 24 vCPUs
az quota show --scope /subscriptions/{sub-id}/providers/Microsoft.Compute/locations/centralus \
  --resource-name standardNCadsA100v4Family</code></pre>
</div></div>

<div class="glass rounded-lg p-3">
<div class="flex items-center gap-2 mb-2"><span class="text-xs font-bold text-indigo-300">1.3</span><span class="text-xs font-bold text-white">Create AKS Cluster</span></div>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>az aks create \
  --resource-group rg-eagles-ai-inference \
  --name aks-eagles-inference \
  --location centralus \
  --node-count 1 \
  --node-vm-size Standard_D2s_v3 \
  --enable-managed-identity \
  --generate-ssh-keys</code></pre>
</div></div>

<div class="glass rounded-lg p-3">
<div class="flex items-center gap-2 mb-2"><span class="text-xs font-bold text-indigo-300">1.4</span><span class="text-xs font-bold text-white">Add GPU Spot Node Pool</span><span class="tag bg-emerald-500/20 text-emerald-300">CRITICAL</span></div>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>az aks nodepool add \
  --resource-group rg-eagles-ai-inference \
  --cluster-name aks-eagles-inference \
  --name gpuspot \
  --node-count 0 \
  --node-vm-size Standard_NC24ads_A100_v4 \
  --priority Spot \
  --eviction-policy Delete \
  --spot-max-price -1 \
  --node-taints sku=gpu:NoSchedule \
  --enable-cluster-autoscaler \
  --min-count 0 --max-count 2 \
  --scale-down-mode Deallocate \
  --labels workload=ai-inference --no-wait</code></pre>
</div>
<div class="glass-green rounded-lg p-2 mt-2"><p class="text-[10px] text-emerald-300"><strong>--scale-down-mode Deallocate</strong>: Preserves OS disk + image cache. Resume: 2.5-5 min vs 8-14 min.</p></div>
</div>

<div class="glass rounded-lg p-3">
<div class="flex items-center gap-2 mb-2"><span class="text-xs font-bold text-indigo-300">1.5</span><span class="text-xs font-bold text-white">Install NVIDIA Device Plugin</span></div>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>kubectl get daemonset -n kube-system | grep nvidia
kubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.18.0/deployments/static/nvidia-device-plugin.yml
kubectl describe node -l workload=ai-inference | grep nvidia.com/gpu</code></pre>
</div></div>

</div></div>

<!-- Phase 2 -->
<div class="glass-purple rounded-xl p-4 mb-4">
<h3 class="text-sm font-bold text-purple-300 mb-1">Phase 2: vLLM Deployment (Week 1-2)</h3>
<div class="space-y-3">

<div class="glass rounded-lg p-3">
<div class="flex items-center gap-2 mb-2"><span class="text-xs font-bold text-purple-300">2.1</span><span class="text-xs font-bold text-white">Build + Push vLLM Image</span></div>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>az acr login --name acreaglesinference
docker build -t acreaglesinference.azurecr.io/vllm-openai:v0.15.1 -f Dockerfile.vllm .
docker push acreaglesinference.azurecr.io/vllm-openai:v0.15.1</code></pre>
</div></div>

<div class="glass rounded-lg p-3">
<div class="flex items-center gap-2 mb-2"><span class="text-xs font-bold text-purple-300">2.2</span><span class="text-xs font-bold text-white">Deploy vLLM on AKS</span></div>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>kubectl apply -f namespace.yaml
kubectl apply -f model-pvc.yaml
kubectl apply -f vllm-deployment.yaml
kubectl apply -f vllm-service.yaml
kubectl logs -f -n ai-inference deployment/vllm-server</code></pre>
</div>
<div class="glass-amber rounded-lg p-2 mt-2"><p class="text-[10px] text-amber-300">First start downloads ~20GB from HuggingFace. PVC caches for next starts.</p></div>
</div>

</div></div>

<!-- Phase 3 -->
<div class="glass-cyan rounded-xl p-4 mb-4">
<h3 class="text-sm font-bold text-cyan-300 mb-1">Phase 3: LiteLLM Gateway (Week 2)</h3>
<div class="space-y-3">

<div class="glass rounded-lg p-3">
<div class="flex items-center gap-2 mb-2"><span class="text-xs font-bold text-cyan-300">3.1</span><span class="text-xs font-bold text-white">Create Secrets + Deploy</span></div>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>MASTER_KEY=$(openssl rand -hex 16)
kubectl create secret generic litellm-secrets \
  --namespace ai-inference \
  --from-literal=master-key="sk-eagles-$MASTER_KEY" \
  --from-literal=anthropic-api-key="YOUR_ANTHROPIC_KEY"

kubectl apply -f litellm-config.yaml
kubectl apply -f litellm-deployment.yaml
kubectl get svc -n ai-inference litellm-gateway-svc</code></pre>
</div></div>

<div class="glass rounded-lg p-3">
<div class="flex items-center gap-2 mb-2"><span class="text-xs font-bold text-cyan-300">3.2</span><span class="text-xs font-bold text-white">Test Gateway</span></div>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>curl http://LITELLM_IP:4000/health
curl -X POST http://LITELLM_IP:4000/v1/messages \
  -H "Content-Type: application/json" \
  -H "x-api-key: sk-eagles-MASTER_KEY" \
  -H "anthropic-version: 2023-06-01" \
  -d '{"model":"claude-opus-4-6","max_tokens":100,"messages":[{"role":"user","content":"Hello!"}]}'</code></pre>
</div></div>

</div></div>

<!-- Phase 4 -->
<div class="glass-green rounded-xl p-4 mb-4">
<h3 class="text-sm font-bold text-emerald-300 mb-1">Phase 4: Claude Code Integration (Week 3)</h3>
<div class="space-y-3">

<div class="glass rounded-lg p-3">
<div class="flex items-center gap-2 mb-2"><span class="text-xs font-bold text-emerald-300">4.1</span><span class="text-xs font-bold text-white">Configure Each Developer</span><span class="tag bg-emerald-500/20 text-emerald-300">ALL 6 DEVS</span></div>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code># Add to shell profile (~/.bashrc, ~/.zshrc, or $PROFILE)
export ANTHROPIC_BASE_URL="http://LITELLM_INTERNAL_LB_IP:4000"
export ANTHROPIC_AUTH_TOKEN="sk-eagles-MASTER_KEY"
# All Claude Code requests now route to Qwen2.5 via vLLM (transparent)</code></pre>
</div>
<div class="glass-green rounded-lg p-2 mt-2"><p class="text-[10px] text-emerald-300">Verified from official Claude Code LLM gateway docs. Supports tool_use, streaming, extended thinking.</p></div>
</div>

</div></div>
</div>

<!-- SECTION 5: SMART-SCALE -->
<div id="smart-scale" class="section-anchor glass rounded-2xl p-6 mb-6">
<div class="flex items-center gap-2 mb-4">
<div class="w-2 h-2 rounded-full bg-cyan-400 pulse"></div>
<h2 class="text-xl font-bold text-cyan-400">SMART-SCALE Auto-Shutdown</h2>
</div>

<div class="glass-cyan rounded-xl p-4 mb-4">
<h3 class="text-sm font-bold text-cyan-300 mb-3">How It Works</h3>
<pre class="text-cyan-300" style="font-size:11px;line-height:1.4">
User sends request to Claude Code CLI
        |
        v
+--[ LiteLLM Gateway (CPU, always-on) ]------+
|                                              |
|  Is vLLM backend healthy?                   |
|     |                   |                    |
|    YES                  NO                   |
|     |                   |                    |
|  Forward to vLLM    1. Fallback to Claude API (instant)
|  (normal path)      2. Trigger GPU scale-up
|                     3. KEDA HTTP interceptor buffers requests
|                     4. GPU node resumes (3-5 min)
|                     5. vLLM loads model, Ready
|                     6. Interceptor forwards requests
+----------------------------------------------+
        | (after 15min idle)
+--[ KEDA ScaledObject: replicas 1-&gt;0 ]------+
|  Cluster Autoscaler: Deallocate node         |
|  GPU cost: $0/hr while deallocated           |
+----------------------------------------------+
</pre>
</div>

<div class="glass rounded-xl p-4 mb-4">
<h3 class="text-sm font-bold text-white mb-3">Cold-Start Timeline (Deallocate Resume)</h3>
<div class="space-y-2">
<div class="flex items-center gap-2"><div class="cold-start-bar bg-indigo-600" style="width:15%">VM power-on</div><span class="text-[10px] text-gray-500">30-60s</span></div>
<div class="flex items-center gap-2"><div class="cold-start-bar bg-purple-600" style="width:12%">OS boot + kubelet</div><span class="text-[10px] text-gray-500">30-45s</span></div>
<div class="flex items-center gap-2"><div class="cold-start-bar bg-amber-600" style="width:10%">NVIDIA driver</div><span class="text-[10px] text-gray-500">20-40s</span></div>
<div class="flex items-center gap-2"><div class="cold-start-bar bg-cyan-600" style="width:10%">Node joins AKS</div><span class="text-[10px] text-gray-500">20-40s</span></div>
<div class="flex items-center gap-2"><div class="cold-start-bar bg-emerald-600" style="width:25%">vLLM model load (PVC)</div><span class="text-[10px] text-gray-500">45-90s</span></div>
<div class="flex items-center gap-2"><div class="cold-start-bar bg-rose-600" style="width:5%">Health check</div><span class="text-[10px] text-gray-500">10-20s</span></div>
</div>
<div class="glass-green rounded-lg p-2 mt-3">
<p class="text-xs text-emerald-300"><strong>Total: 2.5-5 min</strong> (vs 8-14 min with Delete mode). During cold start, LiteLLM falls back to Claude Max -- zero user-visible downtime.</p>
</div>
</div>

<div class="grid md:grid-cols-2 gap-4">
<div class="glass rounded-xl p-4">
<h3 class="text-sm font-bold text-white mb-2">Deallocate vs Delete</h3>
<table>
<thead><tr><th>Dimension</th><th class="text-rose-400">Delete</th><th class="text-emerald-400">Deallocate</th></tr></thead>
<tbody>
<tr><td class="text-xs">Resume time</td><td class="text-xs text-rose-400">8-14 min</td><td class="text-xs text-emerald-400 font-bold">2.5-5 min</td></tr>
<tr><td class="text-xs">Image cache</td><td class="text-xs text-rose-400">Lost</td><td class="text-xs text-emerald-400">Preserved</td></tr>
<tr><td class="text-xs">OS disk</td><td class="text-xs text-rose-400">Destroyed</td><td class="text-xs text-emerald-400">Retained</td></tr>
<tr><td class="text-xs">Cost stopped</td><td class="text-xs">$0</td><td class="text-xs text-emerald-400">~$5/mo disk</td></tr>
</tbody>
</table>
</div>
<div class="glass rounded-xl p-4">
<h3 class="text-sm font-bold text-white mb-2">Setup KEDA</h3>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>az aks update \
  --resource-group rg-eagles-ai-inference \
  --name aks-eagles-inference \
  --enable-keda

helm repo add kedahttp https://kedacore.github.io/charts
helm install keda-http-add-on kedahttp/keda-add-ons-http \
  --namespace keda \
  --set interceptor.responseHeaderTimeout=900 \
  --set interceptor.waitTimeout=900

kubectl apply -f keda-http-scaled-object.yaml</code></pre>
</div></div>
</div>
</div>

<!-- SECTION 6: OPERATIONS -->
<div id="operations" class="section-anchor glass rounded-2xl p-6 mb-6">
<div class="flex items-center gap-2 mb-4">
<div class="w-2 h-2 rounded-full bg-orange-400 pulse"></div>
<h2 class="text-xl font-bold text-orange-400">Daily Operations</h2>
</div>

<div class="grid md:grid-cols-2 gap-4">
<div class="glass rounded-xl p-4">
<h3 class="text-sm font-bold text-white mb-3">Health Checks</h3>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>kubectl get pods -n ai-inference
curl http://VLLM_IP:8000/health
curl http://LITELLM_IP:4000/health
kubectl exec -n ai-inference deploy/vllm-server -- nvidia-smi</code></pre>
</div></div>

<div class="glass rounded-xl p-4">
<h3 class="text-sm font-bold text-white mb-3">Cost Monitoring</h3>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>az aks nodepool show \
  --resource-group rg-eagles-ai-inference \
  --cluster-name aks-eagles-inference \
  --name gpuspot \
  --query '{count:count,powerState:powerState.code}'

# LiteLLM admin UI: http://LITELLM_IP:4000/ui</code></pre>
</div></div>

<div class="glass rounded-xl p-4">
<h3 class="text-sm font-bold text-white mb-3">Manual Scale</h3>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code># Force GPU on
az aks nodepool scale -g rg-eagles-ai-inference \
  --cluster-name aks-eagles-inference -n gpuspot --node-count 1

# Force GPU off
az aks nodepool scale -g rg-eagles-ai-inference \
  --cluster-name aks-eagles-inference -n gpuspot --node-count 0

# Restart vLLM
kubectl rollout restart deployment/vllm-server -n ai-inference</code></pre>
</div></div>

<div class="glass rounded-xl p-4">
<h3 class="text-sm font-bold text-white mb-3">Alerts</h3>
<table>
<thead><tr><th>Condition</th><th>Action</th></tr></thead>
<tbody>
<tr><td class="text-xs">GPU util &lt; 5% for 1hr</td><td class="text-emerald-300 text-xs">Auto scale to 0</td></tr>
<tr><td class="text-xs">GPU temp &gt; 85C</td><td class="text-amber-300 text-xs">Alert team</td></tr>
<tr><td class="text-xs">vLLM error &gt; 5%</td><td class="text-rose-300 text-xs">Fallback all to Claude</td></tr>
<tr><td class="text-xs">Credits &lt; $3,000</td><td class="text-amber-300 text-xs">Plan renewal</td></tr>
<tr><td class="text-xs">Spot eviction</td><td class="text-cyan-300 text-xs">Auto-fallback + re-provision</td></tr>
</tbody>
</table>
</div>
</div>
</div>

<!-- SECTION 7: TROUBLESHOOTING -->
<div id="troubleshooting" class="section-anchor glass rounded-2xl p-6 mb-6">
<div class="flex items-center gap-2 mb-4">
<div class="w-2 h-2 rounded-full bg-rose-400 pulse"></div>
<h2 class="text-xl font-bold text-rose-400">Troubleshooting</h2>
</div>

<div class="space-y-3">
<div class="glass-rose rounded-xl p-4">
<h3 class="text-sm font-bold text-rose-300 mb-1">vLLM pod stuck in Pending</h3>
<p class="text-xs text-gray-400 mb-2">GPU node pool has no available nodes or quota issue.</p>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>kubectl describe pod -n ai-inference -l app=vllm-server | tail -20
az aks nodepool show -g rg-eagles-ai-inference --cluster-name aks-eagles-inference -n gpuspot
az vm list-usage --location centralus -o table | grep -i "NC.*A100"</code></pre>
</div></div>

<div class="glass-amber rounded-xl p-4">
<h3 class="text-sm font-bold text-amber-300 mb-1">vLLM OOM (Out of Memory)</h3>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code># Reduce GPU memory utilization in vllm-deployment.yaml:
#   --gpu-memory-utilization=0.90  -&gt;  0.85
# Or reduce context: --max-model-len=32768  -&gt;  16384
kubectl apply -f vllm-deployment.yaml
kubectl rollout restart deployment/vllm-server -n ai-inference</code></pre>
</div></div>

<div class="glass-cyan rounded-xl p-4">
<h3 class="text-sm font-bold text-cyan-300 mb-1">LiteLLM not routing to vLLM</h3>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>kubectl exec -n ai-inference deploy/litellm-gateway -- \
  curl -s http://vllm-server-svc.ai-inference:8000/health
kubectl describe configmap litellm-config -n ai-inference
kubectl logs -n ai-inference deploy/litellm-gateway --tail=50</code></pre>
</div></div>

<div class="glass-purple rounded-xl p-4">
<h3 class="text-sm font-bold text-purple-300 mb-1">Spot Instance Evicted</h3>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code># LiteLLM auto-falls back to Claude API
kubectl get nodes -l workload=ai-inference
# If not auto-recovering:
az aks nodepool scale -g rg-eagles-ai-inference \
  --cluster-name aks-eagles-inference -n gpuspot --node-count 1</code></pre>
</div></div>

<div class="glass-green rounded-xl p-4">
<h3 class="text-sm font-bold text-emerald-300 mb-1">Cold Start &gt; 5 min</h3>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code># Verify Deallocate mode (not Delete)
az aks nodepool show -g rg-eagles-ai-inference \
  --cluster-name aks-eagles-inference -n gpuspot --query scaleDownMode
# Verify image prepuller
kubectl get ds -n ai-inference image-prepuller</code></pre>
</div></div>
</div>
</div>

<!-- SECTION 8: MANIFESTS -->
<div id="manifests" class="section-anchor glass rounded-2xl p-6 mb-6">
<div class="flex items-center gap-2 mb-4">
<div class="w-2 h-2 rounded-full bg-indigo-400 pulse"></div>
<h2 class="text-xl font-bold text-indigo-400">Kubernetes Manifests</h2>
<span class="text-[10px] px-2 py-0.5 rounded bg-indigo-500/20 text-indigo-300">Copy-paste ready</span>
</div>

<div class="grid md:grid-cols-2 gap-4">

<div class="glass rounded-xl p-4">
<div class="text-sm font-bold text-indigo-300 mb-2">namespace.yaml</div>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>apiVersion: v1
kind: Namespace
metadata:
  name: ai-inference
  labels:
    app.kubernetes.io/part-of: eagles-ai-platform</code></pre>
</div></div>

<div class="glass rounded-xl p-4">
<div class="text-sm font-bold text-emerald-300 mb-2">model-pvc.yaml</div>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: vllm-models
  namespace: ai-inference
spec:
  accessModes: [ReadWriteOnce]
  storageClassName: managed-csi-premium
  resources:
    requests:
      storage: 256Gi</code></pre>
</div></div>

<div class="glass rounded-xl p-4 md:col-span-2">
<div class="flex items-center gap-2 mb-2"><div class="text-sm font-bold text-purple-300">vllm-deployment.yaml</div><span class="tag bg-purple-500/20 text-purple-300">GPU Pod</span></div>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-server
  namespace: ai-inference
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vllm-server
  template:
    metadata:
      labels:
        app: vllm-server
    spec:
      tolerations:
      - key: "sku"
        operator: "Equal"
        value: "gpu"
        effect: "NoSchedule"
      - key: "kubernetes.azure.com/scalesetpriority"
        operator: "Equal"
        value: "spot"
        effect: "NoSchedule"
      containers:
      - name: vllm
        image: acreaglesinference.azurecr.io/vllm-openai:v0.15.1
        command: ["python3", "-m", "vllm.entrypoints.openai.api_server"]
        args:
        - --model=Qwen/Qwen2.5-Coder-32B-Instruct-AWQ
        - --quantization=awq_marlin
        - --max-model-len=32768
        - --enable-prefix-caching
        - --gpu-memory-utilization=0.90
        - --port=8000
        ports:
        - containerPort: 8000
        resources:
          limits:
            nvidia.com/gpu: "1"
            memory: "48Gi"
            cpu: "8"
          requests:
            nvidia.com/gpu: "1"
            memory: "32Gi"
            cpu: "4"
        volumeMounts:
        - name: model-cache
          mountPath: /root/.cache/huggingface
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 180
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 180
          periodSeconds: 10
      volumes:
      - name: model-cache
        persistentVolumeClaim:
          claimName: vllm-models
---
apiVersion: v1
kind: Service
metadata:
  name: vllm-server-svc
  namespace: ai-inference
spec:
  selector:
    app: vllm-server
  ports:
  - port: 8000
    targetPort: 8000</code></pre>
</div></div>

<div class="glass rounded-xl p-4 md:col-span-2">
<div class="flex items-center gap-2 mb-2"><div class="text-sm font-bold text-cyan-300">litellm-config.yaml</div><span class="tag bg-cyan-500/20 text-cyan-300">ConfigMap</span></div>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>apiVersion: v1
kind: ConfigMap
metadata:
  name: litellm-config
  namespace: ai-inference
data:
  config.yaml: |
    model_list:
      - model_name: claude-opus-4-6
        litellm_params:
          model: openai/Qwen2.5-Coder-32B-Instruct-AWQ
          api_base: http://vllm-server-svc.ai-inference:8000/v1
          api_key: "none"
      - model_name: "*"
        litellm_params:
          model: openai/Qwen2.5-Coder-32B-Instruct-AWQ
          api_base: http://vllm-server-svc.ai-inference:8000/v1
          api_key: "none"
      - model_name: claude-real
        litellm_params:
          model: anthropic/claude-opus-4-6
          api_key: os.environ/ANTHROPIC_API_KEY
    router_settings:
      routing_strategy: simple-shuffle
      num_retries: 2
      timeout: 120
      fallbacks: [{"claude-opus-4-6": ["claude-real"]}]
    general_settings:
      master_key: os.environ/LITELLM_MASTER_KEY</code></pre>
</div></div>

<div class="glass rounded-xl p-4 md:col-span-2">
<div class="flex items-center gap-2 mb-2"><div class="text-sm font-bold text-cyan-300">litellm-deployment.yaml</div><span class="tag bg-cyan-500/20 text-cyan-300">CPU Pod + Internal LB</span></div>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: litellm-gateway
  namespace: ai-inference
spec:
  replicas: 2
  selector:
    matchLabels:
      app: litellm-gateway
  template:
    metadata:
      labels:
        app: litellm-gateway
    spec:
      containers:
      - name: litellm
        image: ghcr.io/berriai/litellm:main-latest
        args: ["--config", "/config/config.yaml", "--port", "4000"]
        ports:
        - containerPort: 4000
        env:
        - name: ANTHROPIC_API_KEY
          valueFrom:
            secretKeyRef:
              name: litellm-secrets
              key: anthropic-api-key
        - name: LITELLM_MASTER_KEY
          valueFrom:
            secretKeyRef:
              name: litellm-secrets
              key: master-key
        resources:
          requests: { memory: "512Mi", cpu: "500m" }
          limits: { memory: "1Gi", cpu: "1" }
        volumeMounts:
        - name: config
          mountPath: /config
      volumes:
      - name: config
        configMap:
          name: litellm-config
---
apiVersion: v1
kind: Service
metadata:
  name: litellm-gateway-svc
  namespace: ai-inference
  annotations:
    service.beta.kubernetes.io/azure-load-balancer-internal: "true"
spec:
  type: LoadBalancer
  selector:
    app: litellm-gateway
  ports:
  - port: 4000
    targetPort: 4000</code></pre>
</div></div>

<div class="glass rounded-xl p-4">
<div class="flex items-center gap-2 mb-2"><div class="text-sm font-bold text-amber-300">keda-http-scaled-object.yaml</div></div>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>apiVersion: http.keda.sh/v1alpha1
kind: HTTPScaledObject
metadata:
  name: vllm-autoscale
  namespace: ai-inference
spec:
  hosts:
    - vllm.internal
  pathPrefixes:
    - /v1/
  scaleTargetRef:
    name: vllm-server
    kind: Deployment
    apiVersion: apps/v1
    service: vllm-server-svc
    port: 8000
  replicas:
    min: 0
    max: 2
  scalingMetric:
    requestRate:
      granularity: 1s
      targetValue: "5"
      window: 60s
  scaledownPeriod: 900</code></pre>
</div></div>

<div class="glass rounded-xl p-4">
<div class="flex items-center gap-2 mb-2"><div class="text-sm font-bold text-orange-300">Dockerfile.vllm</div></div>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>FROM vllm/vllm-openai:v0.15.1
ENV VLLM_ATTENTION_BACKEND=FLASH_ATTN
HEALTHCHECK --interval=30s --timeout=10s \
  --start-period=120s --retries=5 \
  CMD curl -f http://localhost:8000/health || exit 1</code></pre>
</div></div>

<div class="glass rounded-xl p-4">
<div class="flex items-center gap-2 mb-2"><div class="text-sm font-bold text-indigo-300">image-prepuller.yaml</div></div>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: vllm-image-prepuller
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app: image-prepuller
  template:
    metadata:
      labels:
        app: image-prepuller
    spec:
      nodeSelector:
        workload: ai-inference
      tolerations:
      - key: "sku"
        operator: "Equal"
        value: "gpu"
        effect: "NoSchedule"
      initContainers:
      - name: pull-vllm
        image: acreaglesinference.azurecr.io/vllm-openai:v0.15.1
        command: ["echo", "Image pre-pulled"]
        resources:
          requests: { cpu: "100m", memory: "128Mi" }
      containers:
      - name: pause
        image: registry.k8s.io/pause:3.9
        resources:
          requests: { cpu: "1m", memory: "4Mi" }</code></pre>
</div></div>

<div class="glass rounded-xl p-4">
<div class="flex items-center gap-2 mb-2"><div class="text-sm font-bold text-rose-300">gpu-monitoring.yaml</div><span class="tag bg-rose-500/20 text-rose-300">DCGM Exporter</span></div>
<div style="position:relative"><button class="copy-btn" onclick="copyBlock(this)">Copy</button>
<pre><code>apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: dcgm-exporter
  namespace: ai-inference
spec:
  selector:
    matchLabels:
      app: dcgm-exporter
  template:
    metadata:
      labels:
        app: dcgm-exporter
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9400"
    spec:
      tolerations:
      - key: "sku"
        value: "gpu"
        effect: "NoSchedule"
      nodeSelector:
        workload: ai-inference
      containers:
      - name: dcgm
        image: nvcr.io/nvidia/k8s/dcgm-exporter:3.3.0-3.2.0-ubuntu22.04
        ports:
        - containerPort: 9400
        resources:
          requests: { memory: "128Mi", cpu: "100m" }
          limits: { memory: "512Mi" }</code></pre>
</div></div>

</div>
</div>

<!-- VERIFICATION -->
<div class="glass rounded-2xl p-6 mb-6">
<div class="flex items-center gap-2 mb-4">
<div class="w-2 h-2 rounded-full bg-emerald-400 pulse"></div>
<h2 class="text-xl font-bold text-emerald-400">Verification Checklist</h2>
</div>
<div class="grid md:grid-cols-2 gap-3">
<div class="glass-green rounded-lg p-3 flex items-start gap-2"><span class="text-emerald-400">&#9744;</span><div><div class="text-xs font-bold text-white">Latency</div><div class="text-[10px] text-gray-500">vLLM delivers 30-50 tokens/sec</div></div></div>
<div class="glass-green rounded-lg p-3 flex items-start gap-2"><span class="text-emerald-400">&#9744;</span><div><div class="text-xs font-bold text-white">Concurrent</div><div class="text-[10px] text-gray-500">6 devs simultaneous, all &lt;5s</div></div></div>
<div class="glass-green rounded-lg p-3 flex items-start gap-2"><span class="text-emerald-400">&#9744;</span><div><div class="text-xs font-bold text-white">Failover</div><div class="text-[10px] text-gray-500">Kill vLLM -&gt; LiteLLM routes to Claude</div></div></div>
<div class="glass-green rounded-lg p-3 flex items-start gap-2"><span class="text-emerald-400">&#9744;</span><div><div class="text-xs font-bold text-white">Cost</div><div class="text-[10px] text-gray-500">After 1 month, ~$176-222/mo</div></div></div>
<div class="glass-green rounded-lg p-3 flex items-start gap-2"><span class="text-emerald-400">&#9744;</span><div><div class="text-xs font-bold text-white">Auto-shutdown</div><div class="text-[10px] text-gray-500">15min idle -&gt; GPU Deallocated</div></div></div>
<div class="glass-green rounded-lg p-3 flex items-start gap-2"><span class="text-emerald-400">&#9744;</span><div><div class="text-xs font-bold text-white">Auto-restart</div><div class="text-[10px] text-gray-500">Cold start &lt;5min, Claude fallback works</div></div></div>
<div class="glass-green rounded-lg p-3 flex items-start gap-2"><span class="text-emerald-400">&#9744;</span><div><div class="text-xs font-bold text-white">Gateway</div><div class="text-[10px] text-gray-500">/v1/messages returns Anthropic format</div></div></div>
<div class="glass-green rounded-lg p-3 flex items-start gap-2"><span class="text-emerald-400">&#9744;</span><div><div class="text-xs font-bold text-white">Quality</div><div class="text-[10px] text-gray-500">Compare Qwen vs Claude on 10 tasks</div></div></div>
</div>
</div>

<!-- FOOTER -->
<div class="glass rounded-2xl p-5 mt-8">
<div class="flex items-center justify-between flex-wrap gap-4">
<div>
<div class="flex items-center gap-3 mb-1">
<div class="w-6 h-6 rounded-lg bg-gradient-to-br from-indigo-500 to-purple-600 flex items-center justify-center text-white font-bold text-xs">E</div>
<span class="text-sm font-bold text-white">EAGLES AI Platform Runbook v1.0</span>
</div>
<p class="text-xs text-gray-500">Generated 2026-02-19 | Team: RH-OptimERP | rg-eagles-ai-inference</p>
</div>
<div class="flex flex-wrap gap-3 text-xs">
<div class="glass-accent rounded-lg px-3 py-2"><span class="text-gray-500">AKS:</span><span class="text-indigo-300 font-mono ml-1">aks-eagles-inference</span></div>
<div class="glass-green rounded-lg px-3 py-2"><span class="text-gray-500">ACR:</span><span class="text-emerald-300 font-mono ml-1">acreaglesinference</span></div>
<div class="glass-purple rounded-lg px-3 py-2"><span class="text-gray-500">NS:</span><span class="text-purple-300 font-mono ml-1">ai-inference</span></div>
<div class="glass-cyan rounded-lg px-3 py-2"><span class="text-gray-500">vLLM:</span><span class="text-cyan-300 font-mono ml-1">v0.15.1</span></div>
</div>
</div>
</div>

</div>

<script>
function copyBlock(btn) {
  const wrapper = btn.closest('[style*="position:relative"]');
  const pre = wrapper ? wrapper.querySelector('pre') : null;
  const text = pre ? pre.innerText : '';
  navigator.clipboard.writeText(text).then(() => {
    btn.textContent = 'Copied!';
    btn.classList.add('copied');
    setTimeout(() => { btn.textContent = 'Copy'; btn.classList.remove('copied'); }, 2000);
  }).catch(() => {
    btn.textContent = 'Error';
    setTimeout(() => { btn.textContent = 'Copy'; }, 2000);
  });
}

const sections = document.querySelectorAll('.section-anchor');
const navLinks = document.querySelectorAll('.nav-link');
const observer = new IntersectionObserver((entries) => {
  entries.forEach(entry => {
    if (entry.isIntersecting) {
      const id = entry.target.id;
      navLinks.forEach(link => {
        link.classList.toggle('active', link.getAttribute('href') === '#' + id);
      });
    }
  });
}, { rootMargin: '-20% 0px -70% 0px' });
sections.forEach(s => observer.observe(s));
</script>
</body>
</html>